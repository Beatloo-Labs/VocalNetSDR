# VocalNetSDR ğŸ¶ğŸ”

![Image Description](https://i.imgur.com/App5EK9.png "Image")

## Description

VocalNetSDR is a Python-based tool designed for audio processing enthusiasts and researchers ğŸ§. This project allows users to compare the effectiveness of different neural network models on audio tracks by calculating the Signal-to-Distortion Ratio (SDR). It specifically focuses on evaluating how well these models can separate vocals from mixed audio tracks.

The project takes advantage of various Python libraries such as NumPy, SciPy, SoundFile, and tqdm to process audio files, apply filters, and compute SDR metrics. It's highly suitable for those looking to benchmark the performance of neural network models designed for tasks such as vocal extraction, noise reduction, or any form of audio signal processing.

### Key Features

- **Model Comparison:** Dynamically compare multiple neural network models based on their SDR performance on a given dataset of audio tracks ğŸ“Š.
- **Customizable Processing:** Supports custom audio processing models by specifying their names at runtime, making it highly adaptable to different models and use cases ğŸ”§.
- **Parallel Processing:** Utilizes Python's `ThreadPoolExecutor` for concurrent processing, significantly speeding up the computation over large datasets ğŸš€.
- **Progress Tracking:** Integrates `tqdm` for real-time progress updates during the processing of audio tracks ğŸ“ˆ.

## Installation

1. **Clone the repository to your local machine: ğŸ–¥ï¸**

   ```bash
   git clone https://github.com/beatloo-lab/VocalNetSDR.git
   ```

2. **Navigate to the project directory: ğŸ“‚**

   ```bash
   cd VocalNetSDR
   ```

3. **Install the dependencies: ğŸ“¦**

   ```bash
   python -m pip install -r requirements.txt
   ```

## How to Use

1. **Prepare your dataset** by organizing your audio tracks into the project's `songs` directory. Each song should be in its own subdirectory, named as per your choice (e.g., `song1`). Within each song's folder, include the original mixed track and the outputs from your models. The expected file naming convention is as follows:

   - `original_other.wav`: The original background/instrumental track ğŸ¸.
   - `original_vocals.wav`: The original vocals track ğŸ¤.
   - `vocals_<model_name>.wav`: The separated vocals track processed by the model. Replace `<model_name>` with the name of your neural network model. This should match the names provided through the `--models` argument ğŸ§ .

2. **Run the script** with the desired models as arguments. For example, to compare models named "bsroformer" and "instvoc", you would run âš™ï¸:

   ```bash
   python sdr_model_comparison.py --models bsroformer instvoc
   ```

   You can specify any number of models by adding them to the `--models` argument list, separated by spaces.

## Project Structure ğŸ—ï¸

```
VocalNetSDR/
â”‚
â”œâ”€â”€ songs/                        # Directory for songs to be processed ğŸ“
â”‚   â””â”€â”€ song1/                    # Each song in its own directory
â”‚       â”œâ”€â”€ original_other.wav    # Original background/instrumental track
â”‚       â”œâ”€â”€ original_vocals.wav   # Original vocals track
â”‚       â”œâ”€â”€ vocals_bsroformer.wav # Processed vocals track by "bsroformer" model
â”‚       â””â”€â”€ vocals_instvoc.wav    # Processed vocals track by "instvoc" model
â”‚
â”œâ”€â”€ sdr_model_comparison.py       # Main script for running the comparisons ğŸ“œ
â””â”€â”€ requirements.txt              # Python dependencies ğŸ“š
```

Remember, the filenames for processed vocals tracks should follow the pattern `vocals_<model_name>.wav`, where `<model_name>` is dynamically specified via the `--models` command-line argument, allowing you to easily extend the comparison to additional models.
